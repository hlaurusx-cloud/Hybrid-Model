import streamlit as st
import pandas as pd
import numpy as np
import joblib
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.metrics import (
    accuracy_score, auc, roc_curve, confusion_matrix,
    mean_absolute_error, mean_squared_error, r2_score
)
from lightgbm import LGBMClassifier, LGBMRegressor
import warnings
warnings.filterwarnings("ignore")

# ----------------------
# 1. é¡µé¢åŸºç¡€é…ç½®
# ----------------------
st.set_page_config(
    page_title="æ··åˆæ¨¡å‹ï¼ˆí•˜ì´ë¸Œë¦¬ë“œëª¨í˜•ï¼‰åŠ¨æ€æ¡†æ¶",
    page_icon="ğŸ“Š",
    layout="wide"
)

# å…¨å±€çŠ¶æ€ç®¡ç†ï¼ˆå­˜å‚¨å„æ­¥éª¤æ•°æ®/æ¨¡å‹ï¼Œé¿å…åˆ·æ–°ä¸¢å¤±ï¼‰
if "step" not in st.session_state:
    st.session_state.step = 0  # 0:åˆå§‹é¡µ 1:æ•°æ®ä¸Šä¼  2:æ•°æ®é¢„å¤„ç† 3:æ¨¡å‹è®­ç»ƒ 4:é¢„æµ‹ 5:è¯„ä¼°
if "data" not in st.session_state:
    st.session_state.data = {"accept": None, "genied": None, "merged": None}
if "preprocess" not in st.session_state:
    st.session_state.preprocess = {"imputer": None, "scaler": None, "encoders": None, "feature_cols": None, "target_col": None}
if "models" not in st.session_state:
    st.session_state.models = {"lr": None, "lgb": None, "mixed_weights": {"lr": 0.3, "lgb": 0.7}}
if "task" not in st.session_state:
    st.session_state.task = "åˆ†ç±»"  # é»˜è®¤ä¸ºåˆ†ç±»ï¼Œå¯åˆ‡æ¢ä¸ºå›å½’

# ----------------------
# 2. ä¾§è¾¹æ ï¼šæ­¥éª¤å¯¼èˆª + æ ¸å¿ƒé…ç½®
# ----------------------
st.sidebar.title("ğŸ“Œ æ··åˆæ¨¡å‹æ“ä½œæµç¨‹")
st.sidebar.divider()

# æ­¥éª¤å¯¼èˆªæŒ‰é’®
steps = ["åˆå§‹è®¾ç½®", "ä¸Šä¼ æ•°æ®", "æ•°æ®é¢„å¤„ç†", "æ¨¡å‹è®­ç»ƒ", "æ¨¡å‹é¢„æµ‹", "æ•ˆæœè¯„ä¼°"]
for i, step_name in enumerate(steps):
    if st.sidebar.button(step_name, key=f"btn_{i}"):
        st.session_state.step = i

# æ ¸å¿ƒé…ç½®ï¼ˆä»»åŠ¡ç±»å‹ + æ··åˆæƒé‡ï¼‰
st.sidebar.divider()
st.sidebar.subheader("æ ¸å¿ƒé…ç½®")
st.session_state.task = st.sidebar.radio("ä»»åŠ¡ç±»å‹", options=["åˆ†ç±»", "å›å½’"], index=0)

if st.session_state.step >= 3:  # æ¨¡å‹è®­ç»ƒåå¯è°ƒæ•´æƒé‡
    st.sidebar.subheader("æ··åˆæ¨¡å‹æƒé‡")
    lr_weight = st.sidebar.slider(
        "é€»è¾‘å›å½’æƒé‡ï¼ˆå¯è§£é‡Šæ€§ï¼‰",
        min_value=0.0, max_value=1.0, value=st.session_state.models["mixed_weights"]["lr"], step=0.1
    )
    st.session_state.models["mixed_weights"]["lr"] = lr_weight
    st.session_state.models["mixed_weights"]["lgb"] = 1 - lr_weight
    st.sidebar.text(f"LightGBMæƒé‡ï¼ˆé«˜ç²¾åº¦ï¼‰ï¼š{1 - lr_weight:.1f}")

# ----------------------
# 3. ä¸»é¡µé¢ï¼šåˆ†æ­¥éª¤å±•ç¤ºå†…å®¹
# ----------------------
st.title("ğŸ“Š æ··åˆæ¨¡å‹ï¼ˆí•˜ì´ë¸Œë¦¬ë“œëª¨í˜•ï¼‰åŠ¨æ€éƒ¨ç½²æ¡†æ¶")
st.markdown("**æ”¯æŒä¸Šä¼  accept/genied åŸå§‹æ•°æ®ï¼Œä¸€é”®å®Œæˆé¢„å¤„ç†â†’è®­ç»ƒâ†’é¢„æµ‹å…¨æµç¨‹**")
st.divider()

# ----------------------
# æ­¥éª¤0ï¼šåˆå§‹è®¾ç½®ï¼ˆå¼•å¯¼é¡µï¼‰
# ----------------------
if st.session_state.step == 0:
    st.subheader("ğŸ‰ æ¬¢è¿ä½¿ç”¨æ··åˆæ¨¡å‹åŠ¨æ€æ¡†æ¶")
    st.markdown("""
    æœ¬æ¡†æ¶æ”¯æŒ **æ”¶åˆ°æ•°æ®åç›´æ¥å¯¼å…¥ä½¿ç”¨**ï¼Œæ— éœ€æå‰é¢„å¤„ç†æˆ–è®­ç»ƒæ¨¡å‹ï¼Œæ ¸å¿ƒæµç¨‹å¦‚ä¸‹ï¼š
    
    1. **ä¸Šä¼ æ•°æ®**ï¼šä¸Šä¼  accept å’Œ genied ä¸¤ä¸ªåŸå§‹æ–‡ä»¶ï¼ˆCSV/Parquet/Excelï¼‰
    2. **æ•°æ®é¢„å¤„ç†**ï¼šåˆå¹¶æ•°æ®ã€å¡«å……ç¼ºå¤±å€¼ã€ç¼–ç ç±»åˆ«ç‰¹å¾
    3. **æ¨¡å‹è®­ç»ƒ**ï¼šè®­ç»ƒã€Œé€»è¾‘å›å½’+LightGBMã€æ··åˆæ¨¡å‹
    4. **æ¨¡å‹é¢„æµ‹**ï¼šæ”¯æŒå•æ¡è¾“å…¥æˆ–æ‰¹é‡ä¸Šä¼ é¢„æµ‹
    5. **æ•ˆæœè¯„ä¼°**ï¼šå¯¹æ¯”æ··åˆæ¨¡å‹ä¸å•ä¸€æ¨¡å‹çš„æ€§èƒ½
    
    ### é€‚ç”¨åœºæ™¯
    - åˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚ï¼šé¢„æµ‹ç”¨æˆ·æ˜¯å¦æ¥å—æœåŠ¡ã€æ˜¯å¦è¿çº¦ï¼‰
    - å›å½’ä»»åŠ¡ï¼ˆå¦‚ï¼šé¢„æµ‹é”€é‡ã€é‡‘é¢ã€è¯„åˆ†ï¼‰
    
    ### ç‚¹å‡»å·¦ä¾§ã€Œä¸Šä¼ æ•°æ®ã€å¼€å§‹ä½¿ç”¨ï¼
    """)

# ----------------------
# æ­¥éª¤1ï¼šä¸Šä¼ æ•°æ®ï¼ˆæ ¸å¿ƒï¼šæ”¯æŒåŠ¨æ€å¯¼å…¥ä¸¤ä¸ªåŸå§‹æ–‡ä»¶ï¼‰
# ----------------------
elif st.session_state.step == 1:
    st.subheader("ğŸ“¤ ä¸Šä¼ æ•°æ®ï¼ˆaccept + geniedï¼‰")
    st.markdown("æ”¯æŒæ ¼å¼ï¼šCSVã€Parquetã€Excelï¼ˆ.xlsx/.xlsï¼‰")
    
    col1, col2 = st.columns(2)
    
    # ä¸Šä¼  accept æ–‡ä»¶
    with col1:
        st.markdown("### accept æ•°æ®é›†")
        accept_file = st.file_uploader("é€‰æ‹© accept æ–‡ä»¶", type=["csv", "parquet", "xlsx", "xls"], key="accept")
        if accept_file is not None:
            # è¯»å–ä¸åŒæ ¼å¼æ–‡ä»¶
            if accept_file.name.endswith(".csv"):
                df_accept = pd.read_csv(accept_file)
            elif accept_file.name.endswith(".parquet"):
                df_accept = pd.read_parquet(accept_file)
            elif accept_file.name.endswith((".xlsx", ".xls")):
                df_accept = pd.read_excel(accept_file)
            st.session_state.data["accept"] = df_accept
            st.metric("æ•°æ®é‡", f"{len(df_accept):,} è¡Œ Ã— {len(df_accept.columns)} åˆ—")
            st.dataframe(df_accept.head(3), use_container_width=True)
    
    # ä¸Šä¼  genied æ–‡ä»¶
    with col2:
        st.markdown("### genied æ•°æ®é›†")
        genied_file = st.file_uploader("é€‰æ‹© genied æ–‡ä»¶", type=["csv", "parquet", "xlsx", "xls"], key="genied")
        if genied_file is not None:
            if genied_file.name.endswith(".csv"):
                df_genied = pd.read_csv(genied_file)
            elif genied_file.name.endswith(".parquet"):
                df_genied = pd.read_parquet(genied_file)
            elif genied_file.name.endswith((".xlsx", ".xls")):
                df_genied = pd.read_excel(genied_file)
            st.session_state.data["genied"] = df_genied
            st.metric("æ•°æ®é‡", f"{len(df_genied):,} è¡Œ Ã— {len(df_genied.columns)} åˆ—")
            st.dataframe(df_genied.head(3), use_container_width=True)
    
    # æ•°æ®åˆå¹¶ï¼ˆéœ€ç”¨æˆ·æŒ‡å®šå…³è”é”®ï¼‰
    st.divider()
    if st.session_state.data["accept"] is not None and st.session_state.data["genied"] is not None:
        st.markdown("### æ•°æ®åˆå¹¶è®¾ç½®")
        # è‡ªåŠ¨è¯†åˆ«å…±åŒåˆ—ä½œä¸ºå…³è”é”®å€™é€‰
        common_cols = list(set(st.session_state.data["accept"].columns) & set(st.session_state.data["genied"].columns))
        if common_cols:
            join_key = st.selectbox("é€‰æ‹©å…³è”é”®ï¼ˆç”¨äºåˆå¹¶ä¸¤ä¸ªæ•°æ®é›†ï¼‰", options=common_cols, index=0)
        else:
            join_key = st.text_input("æ— å…±åŒåˆ—ï¼Œè¯·è¾“å…¥å…³è”é”®ï¼ˆéœ€ä¸¤ä¸ªæ–‡ä»¶ä¸­å‡å­˜åœ¨ï¼‰")
        
        join_type = st.selectbox("åˆå¹¶æ–¹å¼", options=["å†…è¿æ¥ï¼ˆåªä¿ç•™å…±åŒæ•°æ®ï¼‰", "å·¦è¿æ¥ï¼ˆä¿ç•™acceptå…¨éƒ¨æ•°æ®ï¼‰"], index=0)
        join_type_map = {"å†…è¿æ¥ï¼ˆåªä¿ç•™å…±åŒæ•°æ®ï¼‰": "inner", "å·¦è¿æ¥ï¼ˆä¿ç•™acceptå…¨éƒ¨æ•°æ®ï¼‰": "left"}
        
        if st.button("å¼€å§‹åˆå¹¶æ•°æ®"):
            try:
                df_merged = pd.merge(
                    st.session_state.data["accept"],
                    st.session_state.data["genied"],
                    on=join_key,
                    how=join_type_map[join_type]
                )
                st.session_state.data["merged"] = df_merged
                st.success(f"æ•°æ®åˆå¹¶æˆåŠŸï¼åˆå¹¶åæ•°æ®ï¼š{len(df_merged):,} è¡Œ Ã— {len(df_merged.columns)} åˆ—")
                st.dataframe(df_merged.head(3), use_container_width=True)
            except Exception as e:
                st.error(f"åˆå¹¶å¤±è´¥ï¼š{str(e)}")
    else:
        st.warning("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ªæ•°æ®é›†å†è¿›è¡Œåˆå¹¶")

# ----------------------
# æ­¥éª¤2ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆåŠ¨æ€é€‚é…æ•°æ®ï¼Œæ— éœ€æå‰é…ç½®ï¼‰
# ----------------------
elif st.session_state.step == 2:
    st.subheader("ğŸ§¹ æ•°æ®é¢„å¤„ç†")
    
    if st.session_state.data["merged"] is None:
        st.warning("è¯·å…ˆå®Œæˆã€Œä¸Šä¼ æ•°æ®ã€æ­¥éª¤å¹¶åˆå¹¶æ•°æ®")
    else:
        df_merged = st.session_state.data["merged"]
        
        # 1. æ•°æ®æ¦‚è§ˆï¼ˆç¼ºå¤±å€¼ã€æ•°æ®ç±»å‹ï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("### æ•°æ®åŸºæœ¬ä¿¡æ¯")
            st.write(f"æ€»æ•°æ®é‡ï¼š{len(df_merged):,} è¡Œ Ã— {len(df_merged.columns)} åˆ—")
            st.write("æ•°æ®ç±»å‹åˆ†å¸ƒï¼š")
            st.dataframe(df_merged.dtypes.value_counts().reset_index(), use_container_width=True)
        
        with col2:
            st.markdown("### ç¼ºå¤±å€¼åˆ†å¸ƒ")
            missing_info = df_merged.isnull().sum()[df_merged.isnull().sum() > 0].reset_index()
            missing_info.columns = ["å­—æ®µå", "ç¼ºå¤±å€¼æ•°é‡"]
            if len(missing_info) > 0:
                st.dataframe(missing_info, use_container_width=True)
                fig_missing = px.imshow(df_merged.isnull(), color_continuous_scale="Reds", title="ç¼ºå¤±å€¼çƒ­åŠ›å›¾")
                st.plotly_chart(fig_missing, use_container_width=True)
            else:
                st.success("æ— ç¼ºå¤±å€¼ï¼")
        
        # 2. é¢„å¤„ç†é…ç½®ï¼ˆç”¨æˆ·å¯è°ƒæ•´ï¼‰
        st.divider()
        st.markdown("### é¢„å¤„ç†å‚æ•°è®¾ç½®")
        
        # é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆé¢„æµ‹å˜é‡ï¼‰
        target_col = st.selectbox("é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆéœ€é¢„æµ‹çš„å˜é‡ï¼‰", options=df_merged.columns, index=-1)
        st.session_state.preprocess["target_col"] = target_col
        
        # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡åˆ—å’Œæ— ç”¨åˆ—ï¼‰
        exclude_cols = st.multiselect("é€‰æ‹©éœ€æ’é™¤çš„åˆ—ï¼ˆå¦‚IDã€æ— å…³å­—æ®µï¼‰", options=[col for col in df_merged.columns if col != target_col])
        feature_cols = [col for col in df_merged.columns if col not in exclude_cols + [target_col]]
        st.session_state.preprocess["feature_cols"] = feature_cols
        
        # ç¼ºå¤±å€¼å¤„ç†
        st.markdown("#### ç¼ºå¤±å€¼å¤„ç†")
        impute_strategy = st.selectbox("æ•°å€¼å‹ç¼ºå¤±å€¼å¡«å……æ–¹å¼", options=["ä¸­ä½æ•°", "å‡å€¼", "ä¼—æ•°"], index=0)
        impute_strategy_map = {"ä¸­ä½æ•°": "median", "å‡å€¼": "mean", "ä¼—æ•°": "most_frequent"}
        
        # ç±»åˆ«ç‰¹å¾ç¼–ç 
        st.markdown("#### ç±»åˆ«ç‰¹å¾ç¼–ç ")
        cat_encoding = st.selectbox("ç±»åˆ«å‹ç‰¹å¾ç¼–ç æ–¹å¼", options=["æ ‡ç­¾ç¼–ç ï¼ˆLabelEncoderï¼‰", "ç‹¬çƒ­ç¼–ç ï¼ˆOneHotEncoderï¼‰"], index=0)
        
        # 3. æ‰§è¡Œé¢„å¤„ç†
        if st.button("å¼€å§‹é¢„å¤„ç†"):
            try:
                X = df_merged[feature_cols].copy()
                y = df_merged[target_col].copy()
                
                # åˆ†ç¦»æ•°å€¼å‹å’Œç±»åˆ«å‹ç‰¹å¾
                num_cols = X.select_dtypes(include=["int64", "float64"]).columns
                cat_cols = X.select_dtypes(include=["object", "category"]).columns
                
                # æ•°å€¼å‹é¢„å¤„ç†ï¼šç¼ºå¤±å€¼å¡«å…… + æ ‡å‡†åŒ–
                imputer = SimpleImputer(strategy=impute_strategy_map[impute_strategy])
                X[num_cols] = imputer.fit_transform(X[num_cols])
                
                scaler = StandardScaler()
                X[num_cols] = scaler.fit_transform(X[num_cols])
                
                # ç±»åˆ«å‹é¢„å¤„ç†ï¼šç¼ºå¤±å€¼å¡«å…… + ç¼–ç 
                encoders = {}
                for col in cat_cols:
                    # å¡«å……ç±»åˆ«å‹ç¼ºå¤±å€¼ä¸º"æœªçŸ¥"
                    X[col] = X[col].fillna("æœªçŸ¥").astype(str)
                    
                    if cat_encoding == "æ ‡ç­¾ç¼–ç ï¼ˆLabelEncoderï¼‰":
                        le = LabelEncoder()
                        X[col] = le.fit_transform(X[col])
                        encoders[col] = le
                    else:  # ç‹¬çƒ­ç¼–ç 
                        ohe = OneHotEncoder(sparse_output=False, drop="first")
                        ohe_result = ohe.fit_transform(X[[col]])
                        ohe_cols = [f"{col}_{cat}" for cat in ohe.categories_[0][1:]]  # æ’é™¤ç¬¬ä¸€ä¸ªç±»åˆ«ï¼ˆé¿å…å…±çº¿æ€§ï¼‰
                        X = pd.concat([X.drop(col, axis=1), pd.DataFrame(ohe_result, columns=ohe_cols)], axis=1)
                        encoders[col] = (ohe, ohe_cols)
                
                # ä¿å­˜é¢„å¤„ç†ç»„ä»¶
                st.session_state.preprocess["imputer"] = imputer
                st.session_state.preprocess["scaler"] = scaler
                st.session_state.preprocess["encoders"] = encoders
                st.session_state.preprocess["feature_cols"] = list(X.columns)  # æ›´æ–°åçš„ç‰¹å¾åˆ—ï¼ˆå«ç‹¬çƒ­ç¼–ç åˆ—ï¼‰
                
                # ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®
                st.session_state.data["X_processed"] = X
                st.session_state.data["y_processed"] = y
                
                st.success("æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
                st.markdown(f"é¢„å¤„ç†åç‰¹å¾æ•°ï¼š{len(X.columns)}")
                st.dataframe(X.head(3), use_container_width=True)
            except Exception as e:
                st.error(f"é¢„å¤„ç†å¤±è´¥ï¼š{str(e)}")

# ----------------------
# æ­¥éª¤3ï¼šæ¨¡å‹è®­ç»ƒï¼ˆæ··åˆæ¨¡å‹ï¼šé€»è¾‘å›å½’+LightGBMï¼‰
# ----------------------
elif st.session_state.step == 3:
    st.subheader("ğŸš€ æ··åˆæ¨¡å‹è®­ç»ƒ")
    
    # æ£€æŸ¥é¢„å¤„ç†æ˜¯å¦å®Œæˆ
    if "X_processed" not in st.session_state.data or "y_processed" not in st.session_state.data:
        st.warning("è¯·å…ˆå®Œæˆã€Œæ•°æ®é¢„å¤„ç†ã€æ­¥éª¤")
    else:
        X = st.session_state.data["X_processed"]
        y = st.session_state.data["y_processed"]
        
        # æ•°æ®æ‹†åˆ†ï¼ˆè®­ç»ƒé›†+æµ‹è¯•é›†ï¼‰
        st.markdown("### è®­ç»ƒé…ç½®")
        test_size = st.slider("æµ‹è¯•é›†å æ¯”", min_value=0.1, max_value=0.3, value=0.2, step=0.05)
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y if st.session_state.task == "åˆ†ç±»" else None)
        
        # æ¨¡å‹é€‰æ‹©ï¼ˆæ ¹æ®ä»»åŠ¡ç±»å‹ï¼‰
        if st.session_state.task == "åˆ†ç±»":
            lr_model = LogisticRegression(max_iter=1000)
            lgb_model = LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
        else:  # å›å½’
            lr_model = LinearRegression()
            lgb_model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
        
        # è®­ç»ƒæ¨¡å‹
        if st.button("å¼€å§‹è®­ç»ƒæ¨¡å‹"):
            with st.spinner("æ¨¡å‹è®­ç»ƒä¸­..."):
                # è®­ç»ƒå•ä¸€æ¨¡å‹
                lr_model.fit(X_train, y_train)
                lgb_model.fit(X_train, y_train)
                
                # ä¿å­˜æ¨¡å‹
                st.session_state.models["lr"] = lr_model
                st.session_state.models["lgb"] = lgb_model
                
                # è®­ç»ƒé›†/æµ‹è¯•é›†é¢„æµ‹
                st.session_state.data["X_train"] = X_train
                st.session_state.data["X_test"] = X_test
                st.session_state.data["y_train"] = y_train
                st.session_state.data["y_test"] = y_test
                
                st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                st.markdown("âœ… å·²è®­ç»ƒæ¨¡å‹ï¼š")
                st.markdown("- é€»è¾‘å›å½’ï¼ˆå¯è§£é‡Šæ€§å¼ºï¼‰")
                st.markdown("- LightGBMï¼ˆé«˜ç²¾åº¦ï¼‰")
                st.markdown("- æ··åˆæ¨¡å‹ï¼ˆåŠ æƒèåˆå‰ä¸¤è€…ï¼‰")

# ----------------------
# æ­¥éª¤4ï¼šæ¨¡å‹é¢„æµ‹ï¼ˆå•æ¡/æ‰¹é‡ä¸Šä¼ ï¼‰
# ----------------------
elif st.session_state.step == 4:
    st.subheader("ğŸ¯ æ¨¡å‹é¢„æµ‹")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦è®­ç»ƒå®Œæˆ
    if st.session_state.models["lr"] is None or st.session_state.models["lgb"] is None:
        st.warning("è¯·å…ˆå®Œæˆã€Œæ¨¡å‹è®­ç»ƒã€æ­¥éª¤")
    else:
        # é¢„æµ‹å‡½æ•°ï¼ˆå¤ç”¨é¢„å¤„ç†é€»è¾‘ï¼‰
        def predict(input_data):
            X = input_data.copy()
            preprocess = st.session_state.preprocess
            num_cols = X.select_dtypes(include=["int64", "float64"]).columns
            cat_cols = X.select_dtypes(include=["object", "category"]).columns
            
            # æ•°å€¼å‹é¢„å¤„ç†
            X[num_cols] = preprocess["imputer"].transform(X[num_cols])
            X[num_cols] = preprocess["scaler"].transform(X[num_cols])
            
            # ç±»åˆ«å‹é¢„å¤„ç†
            for col in cat_cols:
                X[col] = X[col].fillna("æœªçŸ¥").astype(str)
                encoder = preprocess["encoders"][col]
                
                if isinstance(encoder, LabelEncoder):
                    # å¤„ç†æœªè§è¿‡çš„ç±»åˆ«
                    X[col] = X[col].replace([x for x in X[col].unique() if x not in encoder.classes_], "æœªçŸ¥")
                    if "æœªçŸ¥" not in encoder.classes_:
                        encoder.classes_ = np.append(encoder.classes_, "æœªçŸ¥")
                    X[col] = encoder.transform(X[col])
                else:  # OneHotEncoder
                    ohe, ohe_cols = encoder
                    ohe_result = ohe.transform(X[[col]])
                    X = pd.concat([X.drop(col, axis=1), pd.DataFrame(ohe_result, columns=ohe_cols)], axis=1)
            
            # ç¡®ä¿ç‰¹å¾åˆ—é¡ºåºä¸€è‡´
            X = X[preprocess["feature_cols"]]
            
            # æ··åˆæ¨¡å‹é¢„æµ‹
            lr_weight = st.session_state.models["mixed_weights"]["lr"]
            lgb_weight = st.session_state.models["mixed_weights"]["lgb"]
            
            if st.session_state.task == "åˆ†ç±»":
                lr_proba = st.session_state.models["lr"].predict_proba(X)[:, 1]
                lgb_proba = st.session_state.models["lgb"].predict_proba(X)[:, 1]
                mixed_proba = lr_weight * lr_proba + lgb_weight * lgb_proba
                pred = (mixed_proba >= 0.5).astype(int)
                return pred, mixed_proba
            else:
                lr_pred = st.session_state.models["lr"].predict(X)
                lgb_pred = st.session_state.models["lgb"].predict(X)
                mixed_pred = lr_weight * lr_pred + lgb_weight * lgb_pred
                return mixed_pred, None
        
        # é¢„æµ‹æ–¹å¼é€‰æ‹©
        predict_mode = st.radio("é¢„æµ‹æ–¹å¼", options=["å•æ¡æ•°æ®è¾“å…¥", "æ‰¹é‡ä¸Šä¼ CSV"])
        
        # å•æ¡è¾“å…¥é¢„æµ‹
        if predict_mode == "å•æ¡æ•°æ®è¾“å…¥":
            st.markdown("#### å•æ¡æ•°æ®è¾“å…¥ï¼ˆè¯·å¡«å†™ç‰¹å¾å€¼ï¼‰")
            feature_cols = st.session_state.preprocess["feature_cols"]
            input_data = {}
            
            # åŠ¨æ€ç”Ÿæˆè¾“å…¥è¡¨å•ï¼ˆæ ¹æ®ç‰¹å¾ç±»å‹ï¼‰
            with st.form("single_pred_form"):
                cols = st.columns(3)
                for i, col in enumerate(feature_cols[:9]):  # æœ€å¤šæ˜¾ç¤º9ä¸ªç‰¹å¾ï¼ˆé¿å…ç•Œé¢æ‹¥æŒ¤ï¼‰
                    with cols[i % 3]:
                        # åˆ¤æ–­ç‰¹å¾ç±»å‹ï¼ˆæ•°å€¼/ç±»åˆ«ï¼ŒåŸºäºé¢„å¤„ç†å‰çš„ä¿¡æ¯ï¼‰
                        if col in st.session_state.data["X_processed"].select_dtypes(include=["int64", "float64"]).columns:
                            input_data[col] = st.number_input(col, value=0.0)
                        else:
                            # ç±»åˆ«ç‰¹å¾ï¼šç”¨è®­ç»ƒé›†ä¸­çš„å”¯ä¸€å€¼ä½œä¸ºé€‰é¡¹
                            unique_vals = st.session_state.data["X_processed"][col].unique()[:10]  # æœ€å¤š10ä¸ªé€‰é¡¹
                            input_data[col] = st.selectbox(col, options=unique_vals)
                
                # æäº¤é¢„æµ‹
                submit_btn = st.form_submit_button("å¼€å§‹é¢„æµ‹")
            
            if submit_btn:
                input_df = pd.DataFrame([input_data])
                pred, proba = predict(input_df)
                
                st.divider()
                st.markdown("### é¢„æµ‹ç»“æœ")
                if st.session_state.task == "åˆ†ç±»":
                    st.metric("é¢„æµ‹ç»“æœ", "æ­£ç±»" if pred[0] == 1 else "è´Ÿç±»")
                    st.metric("æ­£ç±»æ¦‚ç‡", f"{proba[0]:.3f}" if proba is not None else "-")
                else:
                    st.metric("é¢„æµ‹ç»“æœ", f"{pred[0]:.2f}")
        
        # æ‰¹é‡ä¸Šä¼ é¢„æµ‹
        else:
            st.markdown("#### æ‰¹é‡ä¸Šä¼ CSVé¢„æµ‹")
            uploaded_file = st.file_uploader("ä¸Šä¼ åŒ…å«ç‰¹å¾åˆ—çš„CSVæ–‡ä»¶", type=["csv"])
            
            if uploaded_file is not None:
                batch_df = pd.read_csv(uploaded_file)
                st.metric("ä¸Šä¼ æ•°æ®é‡", f"{len(batch_df):,} è¡Œ")
                st.dataframe(batch_df.head(3), use_container_width=True)
                
                if st.button("å¼€å§‹æ‰¹é‡é¢„æµ‹"):
                    with st.spinner("é¢„æµ‹ä¸­..."):
                        pred, proba = predict(batch_df)
                        batch_df["æ··åˆæ¨¡å‹é¢„æµ‹ç»“æœ"] = pred
                        if proba is not None:
                            batch_df["æ­£ç±»æ¦‚ç‡"] = proba.round(3)
                        
                        st.divider()
                        st.markdown("### æ‰¹é‡é¢„æµ‹ç»“æœ")
                        st.dataframe(batch_df[["æ··åˆæ¨¡å‹é¢„æµ‹ç»“æœ"] + (["æ­£ç±»æ¦‚ç‡"] if proba is not None else []) + feature_cols[:3]], use_container_width=True)
                        
                        # ä¸‹è½½ç»“æœ
                        csv = batch_df.to_csv(index=False, encoding="utf-8-sig")
                        st.download_button(
                            label="ä¸‹è½½é¢„æµ‹ç»“æœ",
                            data=csv,
                            file_name="æ··åˆæ¨¡å‹æ‰¹é‡é¢„æµ‹ç»“æœ.csv",
                            mime="text/csv"
                        )

# ----------------------
# æ­¥éª¤5ï¼šæ•ˆæœè¯„ä¼°ï¼ˆæ··åˆæ¨¡å‹ vs å•ä¸€æ¨¡å‹ï¼‰
# ----------------------
elif st.session_state.step == 5:
    st.subheader("ğŸ“ˆ æ¨¡å‹æ•ˆæœè¯„ä¼°")
    
    if st.session_state.models["lr"] is None or st.session_state.models["lgb"] is None:
        st.warning("è¯·å…ˆå®Œæˆã€Œæ¨¡å‹è®­ç»ƒã€æ­¥éª¤")
    else:
        X_test = st.session_state.data["X_test"]
        y_test = st.session_state.data["y_test"]
        lr_model = st.session_state.models["lr"]
        lgb_model = st.session_state.models["lgb"]
        lr_weight = st.session_state.models["mixed_weights"]["lr"]
        lgb_weight = st.session_state.models["mixed_weights"]["lgb"]
        
        # è®¡ç®—å„æ¨¡å‹é¢„æµ‹ç»“æœ
        if st.session_state.task == "åˆ†ç±»":
            lr_pred = lr_model.predict(X_test)
            lgb_pred = lgb_model.predict(X_test)
            lr_proba = lr_model.predict_proba(X_test)[:, 1]
            lgb_proba = lgb_model.predict_proba(X_test)[:, 1]
            mixed_proba = lr_weight * lr_proba + lgb_weight * lgb_proba
            mixed_pred = (mixed_proba >= 0.5).astype(int)
            
            # è®¡ç®—åˆ†ç±»æŒ‡æ ‡
            def calc_class_metrics(y_true, y_pred, y_proba):
                acc = accuracy_score(y_true, y_pred)
                fpr, tpr, _ = roc_curve(y_true, y_proba)
                auc_score = auc(fpr, tpr)
                return {"å‡†ç¡®ç‡": acc, "AUC": auc_score}
            
            lr_metrics = calc_class_metrics(y_test, lr_pred, lr_proba)
            lgb_metrics = calc_class_metrics(y_test, lgb_pred, lgb_proba)
            mixed_metrics = calc_class_metrics(y_test, mixed_pred, mixed_proba)
            
            metrics_df = pd.DataFrame({
                "æ¨¡å‹": ["é€»è¾‘å›å½’", "LightGBM", "æ··åˆæ¨¡å‹"],
                "å‡†ç¡®ç‡": [lr_metrics["å‡†ç¡®ç‡"], lgb_metrics["å‡†ç¡®ç‡"], mixed_metrics["å‡†ç¡®ç‡"]],
                "AUC": [lr_metrics["AUC"], lgb_metrics["AUC"], mixed_metrics["AUC"]]
            }).round(3)
        
        else:  # å›å½’
            lr_pred = lr_model.predict(X_test)
            lgb_pred = lgb_model.predict(X_test)
            mixed_pred = lr_weight * lr_pred + lgb_weight * lgb_pred
            
            # è®¡ç®—å›å½’æŒ‡æ ‡
            def calc_reg_metrics(y_true, y_pred):
                mae = mean_absolute_error(y_true, y_pred)
                rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                r2 = r2_score(y_true, y_pred)
                return {"MAE": mae, "RMSE": rmse, "RÂ²": r2}
            
            lr_metrics = calc_reg_metrics(y_test, lr_pred)
            lgb_metrics = calc_reg_metrics(y_test, lgb_pred)
            mixed_metrics = calc_reg_metrics(y_test, mixed_pred)
            
            metrics_df = pd.DataFrame({
                "æ¨¡å‹": ["é€»è¾‘å›å½’", "LightGBM", "æ··åˆæ¨¡å‹"],
                "MAE": [lr_metrics["MAE"], lgb_metrics["MAE"], mixed_metrics["MAE"]],
                "RMSE": [lr_metrics["RMSE"], lgb_metrics["RMSE"], mixed_metrics["RMSE"]],
                "RÂ²": [lr_metrics["RÂ²"], lgb_metrics["RÂ²"], mixed_metrics["RÂ²"]]
            }).round(3)
        
        # å±•ç¤ºæŒ‡æ ‡å¯¹æ¯”
        st.markdown("### æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        st.dataframe(metrics_df, use_container_width=True)
        
        # å¯è§†åŒ–å¯¹æ¯”
        col1, col2 = st.columns(2)
        
        # åˆ†ç±»ä»»åŠ¡å¯è§†åŒ–
        if st.session_state.task == "åˆ†ç±»":
            with col1:
                st.markdown("### ROC-AUC æ›²çº¿")
                fpr_lr, tpr_lr, _ = roc_curve(y_test, lr_proba)
                fpr_lgb, tpr_lgb, _ = roc_curve(y_test, lgb_proba)
                fpr_mixed, tpr_mixed, _ = roc_curve(y_test, mixed_proba)
                
                fig_auc = go.Figure()
                fig_auc.add_trace(go.Scatter(x=fpr_lr, y=tpr_lr, name=f"é€»è¾‘å›å½’ (AUC={lr_metrics['AUC']:.3f})"))
                fig_auc.add_trace(go.Scatter(x=fpr_lgb, y=tpr_lgb, name=f"LightGBM (AUC={lgb_metrics['AUC']:.3f})"))
                fig_auc.add_trace(go.Scatter(x=fpr_mixed, y=tpr_mixed, name=f"æ··åˆæ¨¡å‹ (AUC={mixed_metrics['AUC']:.3f})", line_dash="dash", line_width=3))
                fig_auc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], name="éšæœºçŒœæµ‹", line_color="gray", line_dash="dot"))
                st.plotly_chart(fig_auc, use_container_width=True)
            
            with col2:
                st.markdown("### æ··æ·†çŸ©é˜µï¼ˆæ··åˆæ¨¡å‹ï¼‰")
                cm = confusion_matrix(y_test, mixed_pred)
                cm_df = pd.DataFrame(cm, index=["çœŸå®è´Ÿç±»", "çœŸå®æ­£ç±»"], columns=["é¢„æµ‹è´Ÿç±»", "é¢„æµ‹æ­£ç±»"])
                fig_cm = px.imshow(cm_df, text_auto=True, color_continuous_scale="Blues")
                st.plotly_chart(fig_cm, use_container_width=True)
        
        # å›å½’ä»»åŠ¡å¯è§†åŒ–
        else:
            with col1:
                st.markdown("### é¢„æµ‹å€¼ vs çœŸå®å€¼ï¼ˆæ··åˆæ¨¡å‹ï¼‰")
                fig_pred = px.scatter(x=y_test, y=mixed_pred, title="çœŸå®å€¼ vs é¢„æµ‹å€¼", labels={"x": "çœŸå®å€¼", "y": "é¢„æµ‹å€¼"})
                fig_pred.add_trace(go.Scatter(x=[y_test.min(), y_test.max()], y=[y_test.min(), y_test.max()], line_color="red", name="ç†æƒ³æ‹Ÿåˆçº¿"))
                st.plotly_chart(fig_pred, use_container_width=True)
            
            with col2:
                st.markdown("### æ®‹å·®å›¾ï¼ˆæ··åˆæ¨¡å‹ï¼‰")
                residuals = y_test - mixed_pred
                fig_res = px.scatter(x=mixed_pred, y=residuals, title="é¢„æµ‹å€¼ vs æ®‹å·®", labels={"x": "é¢„æµ‹å€¼", "y": "æ®‹å·®"})
                fig_res.add_trace(go.Scatter(x=[mixed_pred.min(), mixed_pred.max()], y=[0, 0], line_color="red", name="æ®‹å·®=0çº¿"))
                st.plotly_chart(fig_res, use_container_width=True)
        
        # æ¨¡å‹è§£é‡Šï¼ˆç‰¹å¾é‡è¦æ€§ï¼‰
        st.divider()
        st.markdown("### æ¨¡å‹è§£é‡Šï¼šæ ¸å¿ƒç‰¹å¾é‡è¦æ€§")
        feature_importance = pd.DataFrame({
            "ç‰¹å¾å": st.session_state.preprocess["feature_cols"],
            "é‡è¦æ€§": lgb_model.feature_importances_
        }).sort_values("é‡è¦æ€§", ascending=False).head(10)
        
        fig_importance = px.bar(feature_importance, x="é‡è¦æ€§", y="ç‰¹å¾å", orientation="h", color="é‡è¦æ€§", color_continuous_scale="viridis")
        st.plotly_chart(fig_importance, use_container_width=True)
